{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_API_KEY = \"sk-jM9iGBxOO_aKjZCoWlVG9A\"\n",
    "PROXY_ENDPOINT = \"https://nova-litellm-proxy.onrender.com\"\n",
    "CARTESIA_API_KEY = \"3b674e04-346d-444b-8c99-43e2a18d7aa2\"\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "gpt = OpenAI(\n",
    "        api_key=TEAM_API_KEY, # set this!!!\n",
    "        base_url=PROXY_ENDPOINT # and this!!!\n",
    "    )\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from cartesia import Cartesia\n",
    "CARTESIA_VOICE_ID = \"794f9389-aac1-45b6-b726-9d9369183238\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Speech to Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def wav2txt(file_path):\n",
    "    \"\"\"\n",
    "    Converts a .wav audio file to str using OpenAI's Whisper model.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the .wav file to transcribe.\n",
    "\n",
    "    Returns:\n",
    "        str: Transcribed text from the audio.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the audio file\n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        # Use Whisper API to transcribe the audio\n",
    "        response = gpt.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file\n",
    "        )\n",
    "    \n",
    "    # Return the transcribed text\n",
    "    return response.text\n",
    "\n",
    "def txt2wav(text, file_path):\n",
    "    \"\"\"\"\n",
    "    Converts text to speech using Cartesia's Sonic model and saves the audio as a .wav file.\n",
    "    \"\"\"\n",
    "    \n",
    "    voice = Cartesia(api_key=CARTESIA_API_KEY)\n",
    "\n",
    "    data = voice.tts.bytes(\n",
    "        model_id=\"sonic-english\",\n",
    "        transcript=text,\n",
    "        voice_id= CARTESIA_VOICE_ID,\n",
    "        output_format={\n",
    "            \"container\": \"wav\",\n",
    "            \"encoding\": \"pcm_f32le\",\n",
    "            \"sample_rate\": 44100,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chicken nuggets.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2wav(\"chicken nuggets\", \"response.wav\")\n",
    "\n",
    "wav2txt(\"/Users/kyuminpark/Documents/NOVA/response.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interactive_conversation(initial_response, temperature=0.5, max_tokens=100, top_p=1.0, initial_context):\n",
    "    # Initialize the message history with the system and user prompts\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": initial_context},\n",
    "        {\"role\": \"user\", \"content\": initial_response}\n",
    "    ]\n",
    "    \n",
    "    # Conduct a 3-turn conversation\n",
    "    for turn in range(5):\n",
    "        # Make a request to the OpenAI API\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                top_p=top_p\n",
    "            )\n",
    "            assistant_reply = response['choices'][0]['message']['content']\n",
    "            print(f\"Assistant: {assistant_reply}\\n\")\n",
    "            \n",
    "            # Get the next user input\n",
    "            user_input = input(\"Your response: \")\n",
    "            \n",
    "            # Append the assistant and user messages to the conversation history\n",
    "            messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "            messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error during API call: {e}\")\n",
    "            break  # Exit the loop if the API call fails\n",
    "\n",
    "# Example usage\n",
    "interactive_conversation(\"Hello, Assistant! Can you help me with something?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8693b43bc3c960bd12088be69eb1c24907cc6494dcb1c82a88b537b173e6236e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
